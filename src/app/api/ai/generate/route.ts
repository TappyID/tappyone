import { NextRequest, NextResponse } from 'next/server'

// Generate image with OpenAI DALL-E
async function generateImage(prompt: string, model: 'dall-e-2' | 'dall-e-3' = 'dall-e-2') {
  try {
    console.log(`üé® Gerando imagem com ${model.toUpperCase()}:`, prompt.substring(0, 100))
    
    const requestBody: any = {
      model,
      prompt: prompt,
      n: 1,
      size: '1024x1024'
    }
    
    // DALL-E 3 tem par√¢metros extras
    if (model === 'dall-e-3') {
      requestBody.quality = 'standard'
      requestBody.style = 'vivid'
    }
    
    const response = await fetch('https://api.openai.com/v1/images/generations', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const error = await response.text()
      console.error('‚ùå Erro do OpenAI:', response.status, error)
      return NextResponse.json({ 
        error: 'Erro ao gerar imagem', 
        details: error 
      }, { status: response.status })
    }

    const result = await response.json()
    const imageUrl = result.data[0]?.url

    console.log('‚úÖ Imagem gerada com sucesso')
    
    // Baixar a imagem e converter para base64 (evitar CORS no frontend)
    console.log('üì• Baixando imagem para base64...')
    const imgResponse = await fetch(imageUrl)
    const imgBuffer = await imgResponse.arrayBuffer()
    const base64Image = Buffer.from(imgBuffer).toString('base64')
    const imageDataUrl = `data:image/png;base64,${base64Image}`

    return NextResponse.json({
      success: true,
      type: 'image',
      imageUrl: imageDataUrl, // Retornar como data URL base64
      imageUrlOriginal: imageUrl, // URL original da OpenAI
      prompt,
      revised_prompt: result.data[0]?.revised_prompt
    })

  } catch (error) {
    console.error('üí• Erro na gera√ß√£o de imagem:', error)
    return NextResponse.json(
      { error: 'Erro interno na gera√ß√£o de imagem' },
      { status: 500 }
    )
  }
}

// Generate audio with OpenAI TTS
async function generateAudio(prompt: string, voice: string = 'nova') {
  try {
    console.log(`üéµ Gerando √°udio com OpenAI TTS (voz: ${voice}):`, prompt.substring(0, 100))
    
    const response = await fetch('https://api.openai.com/v1/audio/speech', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'tts-1', // tts-1 ou tts-1-hd (mais qualidade)
        input: prompt,
        voice: voice, // Voz din√¢mica!
        response_format: 'mp3',
        speed: 1.0 // 0.25 a 4.0
      })
    })

    if (!response.ok) {
      const error = await response.text()
      console.error('‚ùå Erro do OpenAI TTS:', response.status, error)
      return NextResponse.json({ 
        error: 'Erro ao gerar √°udio', 
        details: error 
      }, { status: response.status })
    }

    // Converter response para base64 para enviar ao frontend
    const audioBuffer = await response.arrayBuffer()
    const base64Audio = Buffer.from(audioBuffer).toString('base64')
    const audioDataUrl = `data:audio/mp3;base64,${base64Audio}`

    console.log('‚úÖ √Åudio gerado com sucesso:', {
      size: audioBuffer.byteLength,
      prompt: prompt.substring(0, 50)
    })

    return NextResponse.json({
      success: true,
      type: 'audio',
      message: 'üéµ √Åudio gerado com sucesso!',
      audioUrl: audioDataUrl, // Base64 data URL
      prompt,
      duration_estimate: Math.ceil(prompt.length / 15) // Estimativa: ~15 caracteres por segundo
    })

  } catch (error) {
    console.error('üí• Erro na gera√ß√£o de √°udio:', error)
    return NextResponse.json(
      { error: 'Erro interno na gera√ß√£o de √°udio' },
      { status: 500 }
    )
  }
}

export async function POST(request: NextRequest) {
  try {
    const { prompt, context, type = 'response', voice = 'nova', imageModel = 'dall-e-2' } = await request.json()
    
    if (!prompt) {
      return NextResponse.json({ error: 'Prompt √© obrigat√≥rio' }, { status: 400 })
    }

    console.log('ü§ñ Iniciando gera√ß√£o:', {
      prompt: prompt.substring(0, 100) + '...',
      type,
      hasContext: !!context
    })

    // Handle image generation with OpenAI DALL-E
    if (type === 'image') {
      return await generateImage(prompt, imageModel)
    }

    // Handle audio generation with selected voice
    if (type === 'audio') {
      return await generateAudio(prompt, voice)
    }

    let systemMessage = ''
    
    switch (type) {
      case 'response':
        systemMessage = 'Voc√™ √© um assistente especializado em atendimento ao cliente via WhatsApp. Gere respostas profissionais, amig√°veis e √∫teis. Use uma linguagem natural e brasileira. Seja conciso mas completo.'
        break
      case 'improve':
        systemMessage = 'Voc√™ √© um especialista em comunica√ß√£o. Melhore o texto fornecido mantendo o sentido original, mas tornando-o mais claro, profissional e amig√°vel. Use linguagem brasileira natural.'
        break
      case 'formal':
        systemMessage = 'Transforme o texto em uma vers√£o mais formal e profissional, mantendo a cordialidade. Use linguagem brasileira corporativa.'
        break
      case 'casual':
        systemMessage = 'Transforme o texto em uma vers√£o mais casual e amig√°vel, mantendo o profissionalismo. Use linguagem brasileira descontra√≠da.'
        break
      default:
        systemMessage = 'Voc√™ √© um assistente de atendimento ao cliente. Ajude a criar respostas √∫teis e profissionais.'
    }

    if (context) {
      systemMessage += `\n\nContexto adicional: ${context}`
    }

    const deepseekResponse = await fetch(`${process.env.DEEPSEEK_API_BASE_URL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.DEEPSEEK_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: process.env.DEEPSEEK_MODEL || 'deepseek-chat',
        messages: [
          {
            role: 'system',
            content: systemMessage
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 1000,
        temperature: 0.7,
        stream: false
      })
    })

    if (!deepseekResponse.ok) {
      const errorText = await deepseekResponse.text()
      console.error('‚ùå Erro do DeepSeek:', deepseekResponse.status, errorText)
      return NextResponse.json({ 
        error: 'Erro ao gerar conte√∫do com IA', 
        details: errorText 
      }, { status: deepseekResponse.status })
    }

    const completion = await deepseekResponse.json()
    const generatedText = completion.choices[0]?.message?.content || ''
    
    console.log('‚úÖ Gera√ß√£o conclu√≠da:', {
      text: generatedText.substring(0, 100) + '...',
      length: generatedText.length,
      tokens_used: completion.usage?.total_tokens
    })

    return NextResponse.json({
      success: true,
      text: generatedText,
      type,
      tokens_used: completion.usage?.total_tokens
    })

  } catch (error) {
    console.error('üí• Erro na gera√ß√£o com IA:', error)
    return NextResponse.json(
      { error: 'Erro interno do servidor' },
      { status: 500 }
    )
  }
}
